row_type	challenge_type	time_to_complete	spearman_correlation	krippendorff_coefficient	academic_degree	english_mother_tongue	language_skill	sentence_difficulty	similarity_difficulty	challenge_rating	challenge_count	challenge_feedback	general_feedback	challenge_solved	lemma	count_all	count_solved	challenge_success_probability
	list_challenge	205.12	0.74		yes	no	8.0	7.0	8.0	2.0	2.0	no		False	part			
	list_challenge	312.95	0.74		yes	no	8.0	3.0	4.0	2.0	1.0	No. Image Captcha is likely faster.		False	record			
	list_challenge	46.16	0.75		yes	yes	10.0	10.0	10.0	2.0	3.0	No, it seems problematic.		False	order			
	list_challenge	72.01	0.38		yes		8.0	8.0	7.0	2.0	4.0		The similar items were easy to rank, but among the ones with completely different sense, how one should rank those were much less trivial and obvious.	False	bar			
	list_challenge	101.78	-0.03		yes	no	9.0	9.0	4.0	2.0	3.0			False	twist			
	list_challenge	158.94	1.0		yes	yes	10.0	9.0	9.0	2.0	3.0	I would prefer no captchas, but as it stands in regards to this challenge, Image-Captchas are preferred (which still have their own accessibility constraints).	Initially, it seems to give pereference to native speakers or high level speakers of English. This seems to ask someone more about their ability to understand vocabulary in context. Perhaps young speakers or English learners who encounter this type of captcha might be denied some kind of access. Otherwise, it was an interesting ordering game.	True	bar			
	list_challenge	48.75	0.5		yes	yes	10.0	8.0	8.0	2.0	3.0	I would prefer the image-based one to this as this takes more time and requires more thought.	Some rankings seem subjective to me so I'm not sure there is just one possible answer; one sentence was rather unclear to me the way it was worded. 	False	bank			
	list_challenge	74.56	0.81		yes	no	9.0	1.0	4.0	2.0	1.0	Not really. I think we are in a phase where Captchas are only being (mis)used for cheap data labeling.	Asking for an absolute ordering may be too much, when there are multiple sentences that are not related at all. This will probably introduce noise in your study.	True	record			
	list_challenge	98.55	1.0		yes	no	9.0	6.0	7.0	2.0	2.0	While it would be more fun and I personally might prefer it because of that, I think anyone who has less than near-native proficiency in English would not be able to complete the challenge and thus others might not prefer it.	I think the idea is fun, but the idea of testing if one's a human by testing one's semantic understanding in English is something I find quite problematic. It assumes that every user would be proficient enough to answer the test seeing as it requires near-native proficiency to understand the examples, which is not the case for a lot of people, and particularly disparaging towards non-native speakers coming from a minority background. It is also implied that there is (only) one correct answer to this test, which is never really the case when it comes to  semantics, as people might have different conceptualisations of meaning based on their previous knowledge and how knowledge is mapped and linked in the brain. It might be good to read up on cognitive linguistics/semantics for this study.	True	record			
	list_challenge	67.9	0.23		yes	yes	10.0	6.0	3.0	2.0	3.0	Not really, too exhausting	This takes a LOT of brainpower. If it proves effective, might be good for something you REALLY want to keep bots out of, but it'd be exhausting to do this on a regular basis. It might be better with fewer options, but if you take it down to three then there's a 17% chance to get through by luck, so you're limited there too. Also it's extremely subjective, so the idea of having only one right answer seems absurd to me, and would probably lock out a lot of less-literate humans as well.	False	twist			
	list_challenge	42.7	1.0		yes	no	9.0	8.0	6.0	2.0	1.0	No		True	arm			
	list_challenge	60.26	0.56		yes	yes	10.0	8.0	6.0	2.0	0.0	No, this challenge takes much more time than an image based one.		False	order			
	list_challenge	169.3	1.0		yes	no	1.0	10.0	6.0	2.0	0.0	no		True	order			
	list_challenge	86.65	0.81		yes	no	3.0	6.0	5.0	2.0	1.0			True	tip			
	list_challenge	73.87	1.0		yes	no	8.0	8.0	5.0	2.0	3.0	No, this felt like a lot more effort than an image captcha, which feels a lot more intuitive.	"I feel like it could work with if: 1. the instructions were refined to be more intuitive. E.g. ""Click on all traffic lights"" is much quicker to grasp than ""re-rank the sentences based on semantic similarity of the highlighted word"" (paraphrasing here, but I think you get what I mean :) )2. Maybe multiple pair-wise comparisons would be more intuitive (e.g. in which one of these two sentences the highlighted word is closer to the reference). Not sure if that would have the same robustness though.3. Bit of a side-note, but have you tried giving this task to an LLM? Would be curios to know how it compares "	True	order			
	list_challenge	75.39	0.03		yes	no	8.0	7.0	3.0	2.0	1.0	No		False	twist			
mean		105.93	0.66				8.12	7.12	5.94	2.0	1.94							
median		74.98	0.75				9.0	8.0	6.0	2.0	2.0							
standard_deviation		72.31	0.35				2.55	2.39	2.11	0.0	1.24							
min		42.7	-0.03				1.0	1.0	3.0	2.0	0.0							
max		312.95	1.0				10.0	10.0	10.0	2.0	4.0					16.0	7.0	0.44
